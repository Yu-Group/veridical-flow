{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historical-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from vflow import Vset, build_vset, init_args, dict_to_df, perturbation_stats\n",
    "from vflow.pipeline import build_graph\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 8\n",
    "np.random.seed(31415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emerging-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=3, n_informative=1)\n",
    "\n",
    "# 20% of X entries missing\n",
    "i = np.random.randint(X.shape[0], size=round(X.shape[0]*X.shape[1] * 0.2))\n",
    "j = np.random.randint(X.shape[1], size=i.size)\n",
    "X[i, j] = np.nan\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval)\n",
    "\n",
    "X_train, y_train = init_args([X_train, y_train], names=['X_train', 'y_train'])\n",
    "X_val, y_val = init_args([X_val, y_val], names=['X_val', 'y_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "common-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vflow import Vset\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "preproc_list = [SimpleImputer(strategy='mean'),\n",
    "                SimpleImputer(strategy='median'),\n",
    "                KNNImputer()]\n",
    "\n",
    "# create a Vset which varies over the list of preprocessing methods\n",
    "preproc_set = Vset(\"preproc\", preproc_list, ['mean', 'med', 'knn'], output_matching=True)\n",
    "\n",
    "# create the feature importance Vset\n",
    "feat_imp_set = build_vset('feat_imp', permutation_importance, n_repeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swedish-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from vflow import build_vset\n",
    "\n",
    "# hyperparameters to try\n",
    "RF_params = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'min_samples_split': [2, 10]\n",
    "}\n",
    "\n",
    "# we could instead pass a list of distinct models and corresponding param dicts\n",
    "RF_set = build_vset('RF', RF, RF_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "labeled-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# create a Vset for bootstrapping from data 10 times\n",
    "# we use lazy=True so that the data will not be resampled until needed\n",
    "boot_set = build_vset('boot', resample, reps=10, lazy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concerned-alloy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.7 s, sys: 615 ms, total: 50.3 s\n",
      "Wall time: 50.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<vflow.vset.Vset at 0x7feda4484430>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# bootstrap from training data by calling boot_fun\n",
    "X_trains, y_trains = boot_set(X_train, y_train)\n",
    "\n",
    "# apply three preprocessing methods to each bootstrap sample\n",
    "X_trains = preproc_set.fit_transform(X_trains)\n",
    "\n",
    "# this results in fitting all 4 RF models to each of the 300 boot/preproc combos\n",
    "RF_set.fit(X_trains, y_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dried-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/school/yugroup/projects/pcs_inference/pcs_pipeline/veridical-flow/vflow/pipeline.py:145: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fed717a8af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vflow import build_graph\n",
    "\n",
    "# examine the pipeline graph\n",
    "build_graph(RF_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demanding-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.5 s, sys: 24 ms, total: 25.5 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from vflow import dict_to_df, perturbation_stats\n",
    "\n",
    "# calculate importances\n",
    "importances = feat_imp_set.evaluate(RF_set.out, preproc_set.fit_transform(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instrumental-harbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init-boot</th>\n",
       "      <th>boot</th>\n",
       "      <th>init-preproc</th>\n",
       "      <th>preproc</th>\n",
       "      <th>init-RF</th>\n",
       "      <th>RF</th>\n",
       "      <th>init-feat_imp</th>\n",
       "      <th>init-feat_imp</th>\n",
       "      <th>init-feat_imp</th>\n",
       "      <th>feat_imp</th>\n",
       "      <th>out</th>\n",
       "      <th>out-importances_mean</th>\n",
       "      <th>out-importances_std</th>\n",
       "      <th>out-importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=0,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>mean</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=100, min_samples_split=2)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [-0.04233634837216912, -0...</td>\n",
       "      <td>[-0.04233634837216912, -0.027757007166214875, ...</td>\n",
       "      <td>[0.024924678381603792, 0.01683543513535128, 0....</td>\n",
       "      <td>[[-0.007237119193629127, -0.057076608597207645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=1,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>mean</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=100, min_samples_split=2)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [0.01839422558752039, 0.0...</td>\n",
       "      <td>[0.01839422558752039, 0.042711479268497686, 1....</td>\n",
       "      <td>[0.0036565791683874777, 0.024248707247297843, ...</td>\n",
       "      <td>[[0.023523528952571038, 0.01639838148580597, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=2,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>mean</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=100, min_samples_split=2)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [-0.008302930606616354, 0...</td>\n",
       "      <td>[-0.008302930606616354, 0.0177609561581004, 1....</td>\n",
       "      <td>[0.009404206935710093, 0.007448068014780976, 0...</td>\n",
       "      <td>[[-0.016919521392400827, 0.004778872326435479,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=3,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>mean</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=100, min_samples_split=2)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [-0.011638433089425693, 0...</td>\n",
       "      <td>[-0.011638433089425693, 0.00441122785845068, 1...</td>\n",
       "      <td>[0.004962647257262718, 0.011554546703690473, 0...</td>\n",
       "      <td>[[-0.009525831641231663, -0.01849080904085043,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=6,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>knn</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=300, min_samples_split=10)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [0.0013520311839704258, -...</td>\n",
       "      <td>[0.0013520311839704258, -0.010863592214964172,...</td>\n",
       "      <td>[0.005813794379642768, 0.015146096499531523, 0...</td>\n",
       "      <td>[[-0.004240475135807165, -0.001071218738866619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=7,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>knn</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=300, min_samples_split=10)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [-0.003229574147788091, -...</td>\n",
       "      <td>[-0.003229574147788091, -0.008307924721150458,...</td>\n",
       "      <td>[0.0007484332199679789, 0.007173602910324836, ...</td>\n",
       "      <td>[[-0.0027391744025062614, -0.00428709138113114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=8,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>knn</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=300, min_samples_split=10)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [-0.011348925421541348, 0...</td>\n",
       "      <td>[-0.011348925421541348, 0.017103179568118725, ...</td>\n",
       "      <td>[0.0038008072310313, 0.012277653726929369, 0.1...</td>\n",
       "      <td>[[-0.013432921481068671, -0.006016015632128502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>X_train</td>\n",
       "      <td>(rep=9,)</td>\n",
       "      <td>X_train</td>\n",
       "      <td>knn</td>\n",
       "      <td>y_train</td>\n",
       "      <td>(n_estimators=300, min_samples_split=10)</td>\n",
       "      <td>X_val</td>\n",
       "      <td>X_val</td>\n",
       "      <td>y_val</td>\n",
       "      <td>feat_imp_0</td>\n",
       "      <td>{'importances_mean': [-0.01751267608504507, -0...</td>\n",
       "      <td>[-0.01751267608504507, -0.012979887477715502, ...</td>\n",
       "      <td>[0.005890013857352848, 0.014135737708139744, 0...</td>\n",
       "      <td>[[-0.01622471053173602, -0.02528366758975864, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    init-boot      boot init-preproc preproc  init-RF  \\\n",
       "0     X_train  (rep=0,)      X_train    mean  y_train   \n",
       "1     X_train  (rep=1,)      X_train    mean  y_train   \n",
       "2     X_train  (rep=2,)      X_train    mean  y_train   \n",
       "3     X_train  (rep=3,)      X_train    mean  y_train   \n",
       "..        ...       ...          ...     ...      ...   \n",
       "116   X_train  (rep=6,)      X_train     knn  y_train   \n",
       "117   X_train  (rep=7,)      X_train     knn  y_train   \n",
       "118   X_train  (rep=8,)      X_train     knn  y_train   \n",
       "119   X_train  (rep=9,)      X_train     knn  y_train   \n",
       "\n",
       "                                           RF init-feat_imp init-feat_imp  \\\n",
       "0     (n_estimators=100, min_samples_split=2)         X_val         X_val   \n",
       "1     (n_estimators=100, min_samples_split=2)         X_val         X_val   \n",
       "2     (n_estimators=100, min_samples_split=2)         X_val         X_val   \n",
       "3     (n_estimators=100, min_samples_split=2)         X_val         X_val   \n",
       "..                                        ...           ...           ...   \n",
       "116  (n_estimators=300, min_samples_split=10)         X_val         X_val   \n",
       "117  (n_estimators=300, min_samples_split=10)         X_val         X_val   \n",
       "118  (n_estimators=300, min_samples_split=10)         X_val         X_val   \n",
       "119  (n_estimators=300, min_samples_split=10)         X_val         X_val   \n",
       "\n",
       "    init-feat_imp    feat_imp  \\\n",
       "0           y_val  feat_imp_0   \n",
       "1           y_val  feat_imp_0   \n",
       "2           y_val  feat_imp_0   \n",
       "3           y_val  feat_imp_0   \n",
       "..            ...         ...   \n",
       "116         y_val  feat_imp_0   \n",
       "117         y_val  feat_imp_0   \n",
       "118         y_val  feat_imp_0   \n",
       "119         y_val  feat_imp_0   \n",
       "\n",
       "                                                   out  \\\n",
       "0    {'importances_mean': [-0.04233634837216912, -0...   \n",
       "1    {'importances_mean': [0.01839422558752039, 0.0...   \n",
       "2    {'importances_mean': [-0.008302930606616354, 0...   \n",
       "3    {'importances_mean': [-0.011638433089425693, 0...   \n",
       "..                                                 ...   \n",
       "116  {'importances_mean': [0.0013520311839704258, -...   \n",
       "117  {'importances_mean': [-0.003229574147788091, -...   \n",
       "118  {'importances_mean': [-0.011348925421541348, 0...   \n",
       "119  {'importances_mean': [-0.01751267608504507, -0...   \n",
       "\n",
       "                                  out-importances_mean  \\\n",
       "0    [-0.04233634837216912, -0.027757007166214875, ...   \n",
       "1    [0.01839422558752039, 0.042711479268497686, 1....   \n",
       "2    [-0.008302930606616354, 0.0177609561581004, 1....   \n",
       "3    [-0.011638433089425693, 0.00441122785845068, 1...   \n",
       "..                                                 ...   \n",
       "116  [0.0013520311839704258, -0.010863592214964172,...   \n",
       "117  [-0.003229574147788091, -0.008307924721150458,...   \n",
       "118  [-0.011348925421541348, 0.017103179568118725, ...   \n",
       "119  [-0.01751267608504507, -0.012979887477715502, ...   \n",
       "\n",
       "                                   out-importances_std  \\\n",
       "0    [0.024924678381603792, 0.01683543513535128, 0....   \n",
       "1    [0.0036565791683874777, 0.024248707247297843, ...   \n",
       "2    [0.009404206935710093, 0.007448068014780976, 0...   \n",
       "3    [0.004962647257262718, 0.011554546703690473, 0...   \n",
       "..                                                 ...   \n",
       "116  [0.005813794379642768, 0.015146096499531523, 0...   \n",
       "117  [0.0007484332199679789, 0.007173602910324836, ...   \n",
       "118  [0.0038008072310313, 0.012277653726929369, 0.1...   \n",
       "119  [0.005890013857352848, 0.014135737708139744, 0...   \n",
       "\n",
       "                                       out-importances  \n",
       "0    [[-0.007237119193629127, -0.057076608597207645...  \n",
       "1    [[0.023523528952571038, 0.01639838148580597, 0...  \n",
       "2    [[-0.016919521392400827, 0.004778872326435479,...  \n",
       "3    [[-0.009525831641231663, -0.01849080904085043,...  \n",
       "..                                                 ...  \n",
       "116  [[-0.004240475135807165, -0.001071218738866619...  \n",
       "117  [[-0.0027391744025062614, -0.00428709138113114...  \n",
       "118  [[-0.013432921481068671, -0.006016015632128502...  \n",
       "119  [[-0.01622471053173602, -0.02528366758975864, ...  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the helper dict_to_df converts the output to a pandas.DataFrame\n",
    "# using param_key='out' separates the importance dict into multiple cols\n",
    "importances_df = dict_to_df(importances, param_key='out')\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "streaming-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preproc</th>\n",
       "      <th>RF</th>\n",
       "      <th>X-count</th>\n",
       "      <th>X0-mean</th>\n",
       "      <th>X0-std</th>\n",
       "      <th>X1-mean</th>\n",
       "      <th>X1-std</th>\n",
       "      <th>X2-mean</th>\n",
       "      <th>X2-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>(n_estimators=100, min_samples_split=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>1.413734</td>\n",
       "      <td>0.059397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>(n_estimators=100, min_samples_split=2)</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.007716</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>-0.009908</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>1.406988</td>\n",
       "      <td>0.062152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>(n_estimators=300, min_samples_split=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.005769</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>-0.006782</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>1.355347</td>\n",
       "      <td>0.069970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>(n_estimators=300, min_samples_split=2)</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>0.012924</td>\n",
       "      <td>1.447590</td>\n",
       "      <td>0.058728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>med</td>\n",
       "      <td>(n_estimators=100, min_samples_split=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.003492</td>\n",
       "      <td>0.007709</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>1.468638</td>\n",
       "      <td>0.070566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>med</td>\n",
       "      <td>(n_estimators=100, min_samples_split=2)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>-0.000677</td>\n",
       "      <td>0.029884</td>\n",
       "      <td>1.491641</td>\n",
       "      <td>0.063814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>med</td>\n",
       "      <td>(n_estimators=300, min_samples_split=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>1.459505</td>\n",
       "      <td>0.080740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>med</td>\n",
       "      <td>(n_estimators=300, min_samples_split=2)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.014764</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>1.530841</td>\n",
       "      <td>0.078636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   preproc                                        RF  X-count   X0-mean  \\\n",
       "0      knn  (n_estimators=100, min_samples_split=10)       10 -0.002969   \n",
       "1      knn   (n_estimators=100, min_samples_split=2)       10 -0.007716   \n",
       "2      knn  (n_estimators=300, min_samples_split=10)       10 -0.005769   \n",
       "3      knn   (n_estimators=300, min_samples_split=2)       10 -0.002253   \n",
       "..     ...                                       ...      ...       ...   \n",
       "8      med  (n_estimators=100, min_samples_split=10)       10 -0.003492   \n",
       "9      med   (n_estimators=100, min_samples_split=2)       10  0.002673   \n",
       "10     med  (n_estimators=300, min_samples_split=10)       10  0.002116   \n",
       "11     med   (n_estimators=300, min_samples_split=2)       10  0.002549   \n",
       "\n",
       "      X0-std   X1-mean    X1-std   X2-mean    X2-std  \n",
       "0   0.012915 -0.000128  0.012026  1.413734  0.059397  \n",
       "1   0.008911 -0.009908  0.010928  1.406988  0.062152  \n",
       "2   0.008482 -0.006782  0.010586  1.355347  0.069970  \n",
       "3   0.010559 -0.005499  0.012924  1.447590  0.058728  \n",
       "..       ...       ...       ...       ...       ...  \n",
       "8   0.007709  0.005208  0.022189  1.468638  0.070566  \n",
       "9   0.012697 -0.000677  0.029884  1.491641  0.063814  \n",
       "10  0.012346  0.001404  0.020467  1.459505  0.080740  \n",
       "11  0.014764  0.008233  0.022524  1.530841  0.078636  \n",
       "\n",
       "[12 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count, mean, and std of importances\n",
    "perturbation_stats(importances_df, 'preproc', 'RF', wrt_col='out-importances_mean', prefix='X', split=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
